# Social Intelligence: Emotion prediction in videos

**Project members:** Ved Phadke, Aaron Tae, Madelaine Leitman, Jonah Jung

**Project lead:** Yiling Yun

In this project, we created an interface on Streamlit to predict the emotions of every frame in a video using a series of deep-learning models designed and trained on a dataset called VEATIC. In addition, we evaluated the model from VEATIC by examining the prediction performance in a variety of videos (single-character vs. multi-character, animals & animations vs. humans, landscape vs portrait).

## Original VEATIC
- The original code is [here](https://veatic.github.io/)

- The VEATIC dataset is [here](https://drive.google.com/file/d/1HZIw8RGsRwwENhJlhNJRL88YyfiE442N/view)

- The pre-trained model is [here](https://drive.google.com/file/d/1dRqmx4UWAtB8E6tcj8XEd16Opk6OZCIx/view)

## Model evaluations
We collected a new set of videos and tested the performance of the model trained using the VEATIC dataset.
